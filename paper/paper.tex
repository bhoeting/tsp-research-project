
% Preamble
% ---
\documentclass[11pt,fleqn]{article}

% Packages
% ---
\usepackage[
  left=3cm,
  right=3cm,
  top=2cm,
  bottom=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{clrscode3e}
\usepackage{blkarray}
\usepackage{booktabs}
\usepackage{parskip}
\usepackage{mathptmx}
\usepackage{bigstrut}
\usepackage{mathptmx}
\usepackage{minted}
\usepackage[pdftex,pdfpagelabels,bookmarks,hyperindex,hyperfigures]{hyperref}
\usepackage{apacite}
\usepackage{tikz}


% Use borland colorscheme in minted.
\usemintedstyle{borland}


% Document
% ---
\begin{document}
%\setlength{\abovedisplayskip}{0pt}
%\setlength{\belowdisplayskip}{0pt}
%\setlength{\abovedisplayshortskip}{0pt}
%\setlength{\belowdisplayshortskip}{0pt}

\title{Exploring the Traveling Salesman Problem}
\author{Brennan Hoeting}
\date{}
\maketitle

\section*{Introduction}
This paper will explore the Traveling Salesman Problem (TSP),
a classic NP---hard problem in the field of computer science.
We will first obtain an understanding of the problem. That
is, we will explain the problem, examine its input and output,
and show why solving this problem particularly challenging.
We will present and explain a naive brute force solution to the
problem and analyze it's efficiency.  We will present a better
method for solving the TSP, the Held---Karp algorithm, and explain
it in detail mathematically and with pseudocode.  There is a
smorgasbord of algorithms that improve over the brute force method,
but they all have their drawbacks and none of them run in a polynomial
time complexity.  We will examine a few of these methods in lesser
detail than Held---Karp and look at situations in which one algorithm
is favorable over another.

\section{Understanding the Problem}
\subsection{Overview}
The traveling salesman problem can be described as follows:
Given a set of cities, where there is a distance between
each pair of cities, find a tour (route) that begins at a
starting city, visits each \textit{destination city} exactly once,
and returns to the starting city with the minimum possible
total distance traveled.  We will refer to the tour with the
minimum possible distance traveled as the \textit{optimal tour}.

\subsection{Problem Input}
The problem input is a matrix that defines the distance
between each pair of cities.  We will denote this as
the distance matrix $D = (d_{ij})$, where $d_{ij}$ is
the distance between city $i$ and city $j$.  It is important
to note that the cost (distance) from city $i$ to city $j$ is equal
to the cost from city $j$ to city $i$. This means that our
TSP variation is \textit{undirected}, so we may use a diagnol
matrix to represent the distances.  That is, for every $d_{ij}$
where $i<j$, $d_{ij}$ is the distance between cities $i$ and $j$,
and every $d_{ij}$ where $i\geq j$, is ignored.
\par

In a \textit{directed} variation of the TSP --- such as one that
optimizes for minimum total airfair to travel a tour by plane,
where ticket prices from city $i$ to city $j$ is not necessarily
equal to the ticket price from city $j$ to city $i$ --- we would
store a cost in every value of $d_{ij}$ where $i\neq j$, rather
than storing the costs in a diagnol matrix.  This distinction,
while helpful to be aware of, minimally affects how the problem is
solved in the methods we will explore.
\par

See below for a valid input example for an undirected TSP variation.
Notice, for example, that the distance between city $1$ and city $4$ is
$d_{1,4}=29$.  If we ran into a case while implementing a TSP algorithm
where we are finding the distance between $i$ and $j$ but $j>i$, we
simply retrieve the distance from $d_{ji}$ instead of $d_{ij}$.
\par

\begin{align*}
  d_{ij}=
  \begin{blockarray}{cccccc}
    & j_1 & j_2 & j_3 & j_4 & j_5 \\
  \begin{block}{c(ccccc)}
    i_1 & \cdot & 7 & 37 & 29 & 17 \\
    i_2 & \cdot & \cdot & 31 & 32 & 34 \\
    i_3 & \cdot & \cdot & \cdot & 32 & 42 \\
    i_4 & \cdot & \cdot & \cdot & \cdot & 20 \\
    i_5 & \cdot & \cdot & \cdot & \cdot & \cdot \\
  \end{block}
  \end{blockarray}
\end{align*}

\subsection{Problem Output}
The output for the TSP is also a matrix with the dimensions
$N\times N$, where $N$ is the number of cities.  We will define the output as
the edge matrix $E = (e_{ij})$, where $e_{ij}=1$ if the optimal tour involves
traveling from city $i$ to city $j$.  $e_{ij}=0$ if meaning we will not
travel from city $i$ to city $j$ along the optimal tour.
\par

We use an edge matrix because if we had a graph $G=(V,E)$, $V_i$
would represent city $i$ and $E_{ij}$ would
represent traveling from city $i$ to city $j$ along the optimal tour.
If the graph where visualized, each verticy would be positioned at its
longitude and latitude coordinates and a segment would connect each pair
of verticies $v_i$ and $v_j$ where $e_{ij}=1$.
\par

Below is an example of a valid output for our TSP variation.  Notice that
$e_{3,4}=1$ implying our optimal tour involves traveling from city $3$ to
city $4$.  Observe that when $i<j$, just as the distance matrix $d_{ij}$,
the value in $e_{ij}$ is not used, resulting in another diagonal matrix.
Observe that $e_1$ has two columns that are $1$.  This will always be the
case for a single $e_i$ where $i$ is the city at we we begin and terminate
the tour.  In this case, and throughout the paper, the optimal tour will
always start and end on the first city.
\par

\begin{align*}
  e_{ij}=
  \begin{blockarray}{cccccc}
    & j_1 & j_2 & j_3 & j_4 & j_5 \\
  \begin{block}{c(ccccc)}
    i_1 & \cdot & 1 & 0 & 0 & 1 \\
    i_2 & \cdot & \cdot & 1 & 0 & 0 \\
    i_3 & \cdot & \cdot & \cdot & 1 & 0 \\
    i_4 & \cdot & \cdot & \cdot & \cdot & 1 \\
    i_5 & \cdot & \cdot & \cdot & \cdot & \cdot \\
  \end{block}
  \end{blockarray}
\end{align*}


\section{A Naive Brute Force Algorithm}
\subsection{Overview}
The brute force method for solving the Traveling Salesman Problem has exactly
two redeeming qualities: (1) it is quite simple, making implementation
trivial, and (2) it will produce the correct tour in every TSP instance.
Unfortunately, for instances that contain more than roughly 10 cities, the
algorithm does not finish execution in a reasonable time.  Analyzing the
pseudocode in (2.2), we can get a good idea of why this is the case.
\par
\vspace{0.5cm}


\subsection{Pseudocode}
\begin{codebox}
\Procname{$\proc{OPTIMAL-TOUR}(D:$ distance matrix$)$}
\li $\id{T} \gets$ all permutations of $[2 \twodots \attrib{D}{length}]$
\li $\id{min-dist} \gets \infty$
\li $\id{min-tour} \gets \const{nil}$
\li \For each tour $t \in T$
\li   \Do
        $\id{t} \gets [1] + T + [1]$
\li       $\id{dist} \gets \proc{TOUR-DISTANCE}(D, t)$
\li	  \If $dist < \id{min-dist}$
\li	    \Then
              $\id{min-dist} \gets dist$
\li	      $\id{min-tour} \gets tour$
            \End
       \End

\li    \Return $\proc{MAKE-EDGE-MATRIX}(\id{min-tour})$
\end{codebox}
 
On line $1$, we assign $\id{T}$ to a list containing each permutation of
the seed list $[2 \twodots \attrib{D}{length}]$.  Each list $T_k$ represents
a partial tour such that $T_{k,i+1}$ is visited from $T_{k,i}$.  Each element
$T_{k,i}$ in $T_k$ corresponds to a row index $i$ in the distance matrix $D$.
\par

Notice that we initially exclude our starting city, $1$, from the seed list.
This is to ensure $T$ only includes permutations the destination cities. Next,
for each permutation $t$ in $T$, we append $1$ to the front and back of $t$.
This gives us a complete tour, starting on $1$, visiting each destination
exactly once, and ending on $1$.  Now we may calculate the total distance,
$\id{dist}$, of $t$ by calling the $\proc{TOUR-DISTANCE}(D, t)$ procedure,
which is simply:

\vspace{.27cm}
\hrule
\begin{codebox}
\Procname{$\proc{TOUR-DISTANCE}(t:$ tour, $D:$ distance matrix$)$}
\li $\id{dist} \gets 0$
\li \For $\id{i} \gets 2$ to $\attrib{t}{length}$
\li   \Do
$\id{dist} \gets \id{dist} + D_{\proc{min}(t_{i-1}, t_i), \proc{max}(t_{i-1}, t_i)}$
       \End
\li    \Return $\id{dist}$
\end{codebox}
\vspace{.1cm}
\hrule
\vspace{.05cm}

If $\id{dist} < \id{min-dist}$, we update
$\id{min-dist}$ and $\id{min-tour}$.  Once the loop is finished, we
return an edge matrix to represent the optimal tour using the
$\proc{MAKE-EDGE-MATRIX}()$ procedure, which creates an edge matrix from a tour
represented as a list.
\par


\subsection{Runtime}
Looking at the table below, we can see how the number of potential optimal
paths increases as the number of cities increases.
\par

\bgroup
\def\arraystretch{1.25}
\begin{tabular}{c|r}
  Cities $n$ & Possible Tours $(n-1){!}$ \\
  \hline
  \begin{tabular}{c}
    $4$ \\
    $5$ \\
    $\dots$ \\
    $10$ \\
    $11$ \\
    $12$
  \end {tabular}
  &
  \begin{tabular}{r@{\;{=}\;}l}
    $(4-1){!}$ & $6$ \\
    $(5-1){!}$ & $24$ \\
    $\dots$ & $\dots$ \\
    $(10-1){!}$ & $362,880$ \\
    $(11-1){!}$ & $3,628,800$ \\
    $(12-1){!}$ & $39,916,800$
  \end{tabular}

\end{tabular}
\egroup

The runtime of this method is upper bounded by the amount
of time it takes to generate each possible tour, so we can
say the algorithm is $O((n-1)!) = O(n!)$, where $n$ is the
number of cities.
\par


\section{A Better Algorithm}
\subsection{Overview}
While the brute force algorithm is simple and correct, it
is far too slow for larger inputs.  Fortunately, there are multiple
alternative TSP algorithms with a non-polynomial runtime
that is better than $O(n!)$.  We will explore in detail the
\textit{Held--Karp} algorithm, an $O(2^n)$ solution that uses
dynamic programming \cite{heldkarp}.  Then we will look at it
to the MST approximation algorithm and discuss the advantages
of each approach. 

\subsection{Held--Karp}
The Held--Karp algorithm is an $O(2^n)$ approach to solving the TSP\@.
It is not fast enough to solve TSP instances with a large number of
cities, but the solution for the instances it can solve is guarenteed
to be correct.  The algorithm works as follows:
\par

Suppose $D = (d_{ij})$ is distance
matrix where $d_{ij} = d_{ji}$, $n$ is the number of rows in $D$,
$S$ is a subset of $\{1, 2,\dots,n\}$, and $x\in S$.  We define $C(S, x)$
to be the distance of the optimal tour that starts at $x$, visits each
destination exactly once, and ends at $1$ \cite{heldkarp}.  The recurrence
for $C(S,x)$ is:

\begin{align*}
  C(S, x)=\begin{cases}
    \min\{k\in S-\{x\} : d_{kx} + C(S-\{x\}, k) \}  & \text{if } n>1 \\
    d_{1x}                                          & \text{if } n=1
  \end{cases}
\end{align*}

We obtain the optimal cost from a distance matrix $D$ of size $n$ by calling
$C(\{1,\dots,n\}, 1)$.  We can apply dynamic programming principles to this
problem by storing the cost for each call in a lookup table $H$.  In each
recurrence where $n>1$, if the tuple $(S, x)$ exists in $H$, we can return
$H[(S, x)]$.  Otherwise,  we will compute the cost and store it in $H$.
\par

This alone does not solve the original problem.  We still need to return 
the optimal tour, not just its distance.  We can find the optimal tour
by backtracing through $H$.  We define the optimal tour as $P$ and $B(v)$
as a recurrence that backtraces through $H$:

\begin{align*}
  B(v)=\begin{cases}
    B(H[v])     & \text{if } v \text{\ in\ } H \\
    \const{nil} & \text{otherwise} 
  \end{cases}
\end{align*}

We fill in the values of $P$ by calling $B((\{1,\dots,n\}, 1))$.  On each
recurrence where $v$ is in $H$, we append the second value from the tuple $v$
to $P$.  When $v$ is not in $H$ and $\const{nil}$ is returned from $B(v)$, we
append $1$ to $P$, resulting in the optimal tour.
\par

\subsection{Christofides}
Christofide's algorithm is an $O(n^3)$ approximation algorithm that guarentees
the cost of its solution will be strictly within $3/2$ of the optimal solution
cost.  The algorithm only works on a symmetric distance matrix that satisfies
the triangle inequality \cite{nicos}.  That is, a distance matrix $D=d_{ij}$
may be used if the shortest path to reach every $j$ from
$i$ involves traveling directly to $j$ from $i$, rather than through a path that
includes more than two verticies.
\par

The algorithm works as follows: Given a distance matrix $D=d_{ij}$ and size $n$,
let $G=(V,E)$ where $v_i=i$ for all $i\in [1,\dots,n]$ and $e_{ij}=d_{ij}$.  The
optimal tour starting at $v_1$ is obtained using the following steps:
\begin{enumerate}
  \item Generate a minimum spanning tree, $MST$, rooted at $v_1$ using Prim's algorithm.
  \item Perform a preorder traversal on $MST$ and append the verticies in the order they 
    are visited to list a $T$.
  \item For each verticy in $T$, append it to $T'$ only when it is first visited.  This 
    removes duplicates from $T$ resulting in the optimal tour.
\end{enumerate}

The last step holds since $G$ satisfies the triangle inequality.

\subsection{Nearest Neighbor}
The Nearest Neighbor algorithm is a greedy approximation algorithm
for solving the TSP\@.  It starts at an arbitrary city, then visits
the closest city until each city has been visited once.  After each
visit, the city is added to the optimal tour $T$.  Once each node
has been visited, the starting city is appended to $T$ and $T$ is
returned. \cite{bellmore}
\par

The steps for this algorithm are as follows:
\begin{enumerate}
  \item Pick a starting city $s$, let it be the current city $x$.
  \item Add $x$ to the optimal tour $T$ and mark $x$ as visited.
  \item Determine the closest unvisited city $y$ from $x$.  If no
    unvisited cities exist, goto step 5.
  \item assign $x$ to $y$, repeat step 2.
  \item Add $s$ to $T$, return $T$.
\end{enumerate}

\subsection{Comparing the Three}
We have examined one exact algorithm -- Held-Karp -- and two approximation
algorithms --Christofides and Nearest Neighbor.  The approximation algorithms
have the advantage of being significantly faster than the Held-Karp algorithm,
but they aren't applicable in every case, and they don't always return the optimal
tour for cases in which they are applicable.  The Held-Karp algorithm, on the other
hand, will return the optimal tour in every TSP instance, provided the number of
cities is small enough to allow the algorithm to finish execution in a reasonable
time.
\par

Christofide's algorithm and the Nearest Neighbor algorithm both perform at an
acceptable level (that is, they return the optimal tour enough of the time) for
Euclidean TSP instances.  If a TSP instance is Euclidean, then it satisfies the
triangle inequality.  This property is necessary for Christofide's algorithm to
return the correct tour \cite{nicos} and it greatly increases the probability
that the Nearest Neighbor algorithm will as well \cite{gutin}.
\par

For asymmetric and general symmetric TSP instances, Christofide's algorithm will
never return the optimal tour.  The Nearest Neighbor algorithm, on the other hand,
can find an optimal tour, but it's highly unlikely.  Additionally, for every $n\gte 2$
there exists at least one asymmetric or general symmetric TSP instance for which the
Nearest Neighbor algorithm returns the \textit{worst} tour. \cite{gutin}.  We are
optimizing for correctness over speed and problem size in this paper and will continue
to explore the Held--Karp algorithm.

\subsection{Held-Karp Pseudocode}




% Appendicies
% ---
%\newpage
%\appendix
%\section{Appendices}
%\addcontentsline{toc}{section}{Appendices}
%\renewcommand{\thesubsection}{\Alph{subsection}}
%
%\subsection{Collaboration}
%  I collaborated with Grant Eaton and Luke Artnak.
%
%\newpage
%\subsection{Code Demonstration}
%  \inputminted[frame=lines,linenos=true]{python}{../src/brute_force.py}
%
\newpage
\bibliographystyle{apacite}
\bibliography{biblio}

\end{document}
